#!/usr/bin/env python3
"""
Syst√®me de r√©cup√©ration apr√®s d√©sastre pour PassPrint
Proc√©dures de r√©cup√©ration automatique et manuelle
"""
import os
import json
import shutil
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
import logging
import smtplib
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
import tempfile

from backup_system import backup_system
from monitoring_config import get_monitoring_integration

logger = logging.getLogger(__name__)

class DisasterRecoveryManager:
    """Gestionnaire de r√©cup√©ration apr√®s d√©sastre"""

    def __init__(self, app=None):
        self.app = app
        self.recovery_scripts_dir = Path('recovery_scripts')
        self.recovery_scripts_dir.mkdir(exist_ok=True)
        self.logger = logging.getLogger(__name__)

        # Configuration des seuils de d√©sastre
        self.disaster_thresholds = {
            'database_unavailable_minutes': int(os.getenv('DB_UNAVAILABLE_THRESHOLD', '5')),
            'high_error_rate_percent': float(os.getenv('ERROR_RATE_THRESHOLD', '10.0')),
            'system_resource_exhaustion_percent': float(os.getenv('RESOURCE_THRESHOLD', '95.0')),
            'security_incident_score': int(os.getenv('SECURITY_THRESHOLD', '80'))
        }

    def detect_disaster(self, system_metrics: dict) -> Dict:
        """D√©tecter si une situation de d√©sastre est en cours"""
        try:
            disaster_indicators = []
            severity_score = 0

            # V√©rifier la disponibilit√© de la base de donn√©es
            db_healthy = system_metrics.get('database', {}).get('stats', {}).get('connection_healthy', True)
            if not db_healthy:
                disaster_indicators.append('database_unavailable')
                severity_score += 30

            # V√©rifier le taux d'erreur
            error_rate = self._calculate_error_rate(system_metrics)
            if error_rate > self.disaster_thresholds['high_error_rate_percent']:
                disaster_indicators.append('high_error_rate')
                severity_score += 25

            # V√©rifier l'utilisation des ressources syst√®me
            cpu_usage = system_metrics.get('system', {}).get('cpu', {}).get('percent', 0)
            memory_usage = system_metrics.get('system', {}).get('memory', {}).get('percent', 0)
            disk_usage = system_metrics.get('system', {}).get('disk', {}).get('percent', 0)

            if cpu_usage > self.disaster_thresholds['system_resource_exhaustion_percent']:
                disaster_indicators.append('high_cpu_usage')
                severity_score += 15

            if memory_usage > self.disaster_thresholds['system_resource_exhaustion_percent']:
                disaster_indicators.append('high_memory_usage')
                severity_score += 15

            if disk_usage > self.disaster_thresholds['system_resource_exhaustion_percent']:
                disaster_indicators.append('low_disk_space')
                severity_score += 20

            # V√©rifier le score de s√©curit√©
            security_score = system_metrics.get('security', {}).get('events', {}).get('security_score', 100)
            if security_score < self.disaster_thresholds['security_incident_score']:
                disaster_indicators.append('security_incident')
                severity_score += 25

            # D√©terminer le niveau de s√©v√©rit√©
            if severity_score >= 70:
                disaster_level = 'critical'
            elif severity_score >= 40:
                disaster_level = 'high'
            elif severity_score >= 20:
                disaster_level = 'medium'
            else:
                disaster_level = 'low'

            return {
                'disaster_detected': len(disaster_indicators) > 0,
                'severity': disaster_level,
                'severity_score': severity_score,
                'indicators': disaster_indicators,
                'timestamp': datetime.utcnow().isoformat(),
                'recommendations': self._get_recovery_recommendations(disaster_indicators, disaster_level)
            }

        except Exception as e:
            self.logger.error(f"Erreur d√©tection d√©sastre: {e}")
            return {
                'disaster_detected': False,
                'error': str(e)
            }

    def _calculate_error_rate(self, metrics: dict) -> float:
        """Calculer le taux d'erreur actuel"""
        try:
            log_analysis = metrics.get('application', {}).get('performance', {}).get('log_analysis', {})
            error_count = log_analysis.get('error_count', 0)
            total_lines = log_analysis.get('total_lines', 1)

            return (error_count / total_lines) * 100 if total_lines > 0 else 0

        except Exception:
            return 0.0

    def _get_recovery_recommendations(self, indicators: list, severity: str) -> List[str]:
        """Obtenir les recommandations de r√©cup√©ration"""
        recommendations = []

        if 'database_unavailable' in indicators:
            recommendations.append("Restaurer la base de donn√©es depuis la derni√®re sauvegarde")
            recommendations.append("V√©rifier la connectivit√© r√©seau √† la base de donn√©es")

        if 'high_error_rate' in indicators:
            recommendations.append("Analyser les erreurs dans les logs r√©cents")
            recommendations.append("V√©rifier la charge du serveur et les ressources disponibles")

        if 'high_cpu_usage' in indicators or 'high_memory_usage' in indicators:
            recommendations.append("Red√©marrer les services non essentiels")
            recommendations.append("V√©rifier les processus zombies")

        if 'low_disk_space' in indicators:
            recommendations.append("Lib√©rer de l'espace disque")
            recommendations.append("Archiver les anciens logs et sauvegardes")

        if 'security_incident' in indicators:
            recommendations.append("Activer le mode s√©curit√© renforc√©e")
            recommendations.append("Auditer les acc√®s r√©cents")

        # Recommandations g√©n√©rales selon la s√©v√©rit√©
        if severity == 'critical':
            recommendations.insert(0, "üö® D√âSASTRE CRITIQUE D√âTECT√â - Action imm√©diate requise")
            recommendations.append("Contacter l'√©quipe technique d'urgence")
            recommendations.append("Pr√©parer la restauration compl√®te du syst√®me")

        elif severity == 'high':
            recommendations.insert(0, "‚ö†Ô∏è Probl√®me majeur d√©tect√© - Intervention n√©cessaire")
            recommendations.append("Surveiller l'√©volution de la situation")

        return recommendations

    def initiate_automatic_recovery(self, disaster_info: dict) -> Dict:
        """Initier la r√©cup√©ration automatique"""
        try:
            recovery_result = {
                'recovery_initiated': True,
                'timestamp': datetime.utcnow().isoformat(),
                'actions_taken': [],
                'success': True,
                'errors': []
            }

            severity = disaster_info.get('severity', 'low')

            # Actions automatiques selon la s√©v√©rit√©
            if severity == 'critical':
                # R√©cup√©ration critique
                recovery_result.update(self._execute_critical_recovery())

            elif severity == 'high':
                # R√©cup√©ration majeure
                recovery_result.update(self._execute_major_recovery())

            else:
                # R√©cup√©ration mineure
                recovery_result.update(self._execute_minor_recovery())

            # Cr√©er un rapport de r√©cup√©ration
            self._create_recovery_report(recovery_result)

            return recovery_result

        except Exception as e:
            self.logger.error(f"Erreur r√©cup√©ration automatique: {e}")
            return {
                'recovery_initiated': False,
                'success': False,
                'error': str(e)
            }

    def _execute_critical_recovery(self) -> Dict:
        """Ex√©cuter la r√©cup√©ration critique"""
        actions = []
        errors = []

        try:
            # 1. Cr√©er une sauvegarde d'urgence
            emergency_backup = backup_system.create_snapshot("emergency_before_recovery")
            if emergency_backup[0]:
                actions.append("Sauvegarde d'urgence cr√©√©e")
            else:
                errors.append(f"√âchec sauvegarde d'urgence: {emergency_backup[1]}")

            # 2. Tenter de red√©marrer les services essentiels
            services_restart = self._restart_essential_services()
            if services_restart['success']:
                actions.append("Services essentiels red√©marr√©s")
            else:
                errors.append(f"√âchec red√©marrage services: {services_restart['error']}")

            # 3. Restaurer la derni√®re sauvegarde valide
            latest_backup = self._find_latest_valid_backup()
            if latest_backup:
                restore_result = self._restore_from_backup(latest_backup)
                if restore_result['success']:
                    actions.append(f"Sauvegarde restaur√©e: {latest_backup}")
                else:
                    errors.append(f"√âchec restauration: {restore_result['error']}")
            else:
                errors.append("Aucune sauvegarde valide trouv√©e")

        except Exception as e:
            errors.append(f"Erreur r√©cup√©ration critique: {e}")

        return {
            'actions_taken': actions,
            'errors': errors,
            'success': len(errors) == 0
        }

    def _execute_major_recovery(self) -> Dict:
        """Ex√©cuter la r√©cup√©ration majeure"""
        actions = []
        errors = []

        try:
            # 1. Nettoyer les processus probl√©matiques
            cleanup_result = self._cleanup_problematic_processes()
            if cleanup_result['success']:
                actions.append("Processus probl√©matiques nettoy√©s")
            else:
                errors.append(f"√âchec nettoyage processus: {cleanup_result['error']}")

            # 2. V√©rifier et r√©parer la base de donn√©es
            db_check = self._check_and_repair_database()
            if db_check['success']:
                actions.append("Base de donn√©es v√©rifi√©e et r√©par√©e")
            else:
                errors.append(f"Probl√®me base de donn√©es: {db_check['error']}")

            # 3. Red√©marrer l'application
            app_restart = self._restart_application()
            if app_restart['success']:
                actions.append("Application red√©marr√©e")
            else:
                errors.append(f"√âchec red√©marrage application: {app_restart['error']}")

        except Exception as e:
            errors.append(f"Erreur r√©cup√©ration majeure: {e}")

        return {
            'actions_taken': actions,
            'errors': errors,
            'success': len(errors) == 0
        }

    def _execute_minor_recovery(self) -> Dict:
        """Ex√©cuter la r√©cup√©ration mineure"""
        actions = []
        errors = []

        try:
            # 1. Vider les caches probl√©matiques
            cache_clear = self._clear_problematic_caches()
            if cache_clear['success']:
                actions.append("Caches probl√©matiques vid√©s")
            else:
                errors.append(f"√âchec vidage caches: {cache_clear['error']}")

            # 2. Red√©marrer les workers Celery si n√©cessaire
            celery_restart = self._restart_celery_workers()
            if celery_restart['success']:
                actions.append("Workers Celery red√©marr√©s")
            else:
                errors.append(f"√âchec red√©marrage Celery: {celery_restart['error']}")

        except Exception as e:
            errors.append(f"Erreur r√©cup√©ration mineure: {e}")

        return {
            'actions_taken': actions,
            'errors': errors,
            'success': len(errors) == 0
        }

    def _restart_essential_services(self) -> Dict:
        """Red√©marrer les services essentiels"""
        try:
            # Red√©marrer Redis
            redis_restart = self._restart_service('redis')

            # Red√©marrer PostgreSQL si applicable
            db_restart = self._restart_service('postgresql')

            # Red√©marrer Nginx
            nginx_restart = self._restart_service('nginx')

            success = redis_restart.get('success', False)

            return {
                'success': success,
                'details': {
                    'redis': redis_restart,
                    'database': db_restart,
                    'nginx': nginx_restart
                }
            }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _restart_service(self, service_name: str) -> Dict:
        """Red√©marrer un service sp√©cifique"""
        try:
            if service_name == 'redis':
                # Commande pour red√©marrer Redis
                result = subprocess.run(['sudo', 'systemctl', 'restart', 'redis'],
                                      capture_output=True, text=True, timeout=30)

                return {
                    'success': result.returncode == 0,
                    'output': result.stdout,
                    'error': result.stderr
                }

            elif service_name == 'postgresql':
                # Commande pour red√©marrer PostgreSQL
                result = subprocess.run(['sudo', 'systemctl', 'restart', 'postgresql'],
                                      capture_output=True, text=True, timeout=60)

                return {
                    'success': result.returncode == 0,
                    'output': result.stdout,
                    'error': result.stderr
                }

            elif service_name == 'nginx':
                # Commande pour red√©marrer Nginx
                result = subprocess.run(['sudo', 'systemctl', 'restart', 'nginx'],
                                      capture_output=True, text=True, timeout=30)

                return {
                    'success': result.returncode == 0,
                    'output': result.stdout,
                    'error': result.stderr
                }

            return {'success': False, 'error': f'Service {service_name} non support√©'}

        except subprocess.TimeoutExpired:
            return {'success': False, 'error': f'Timeout red√©marrage {service_name}'}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _cleanup_problematic_processes(self) -> Dict:
        """Nettoyer les processus probl√©matiques"""
        try:
            # Identifier les processus Python zombies ou probl√©matiques
            result = subprocess.run(['pgrep', '-f', 'python.*passprint'],
                                  capture_output=True, text=True)

            if result.returncode == 0:
                pids = result.stdout.strip().split('\n')
                killed_count = 0

                for pid in pids:
                    if pid:
                        try:
                            subprocess.run(['kill', '-TERM', pid], timeout=10)
                            killed_count += 1
                        except:
                            pass

                return {
                    'success': True,
                    'processes_killed': killed_count
                }
            else:
                return {'success': True, 'processes_killed': 0}

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _check_and_repair_database(self) -> Dict:
        """V√©rifier et r√©parer la base de donn√©es"""
        try:
            from config import get_config

            config = get_config()
            db_url = config.SQLALCHEMY_DATABASE_URI

            if 'sqlite' in db_url:
                return self._repair_sqlite_database(db_url)
            elif 'postgresql' in db_url:
                return self._repair_postgresql_database(db_url)
            else:
                return {'success': False, 'error': 'Type de base non support√©'}

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _repair_sqlite_database(self, db_url: str) -> Dict:
        """R√©parer une base SQLite"""
        try:
            db_path = db_url.replace('sqlite:///', '')

            # V√©rifier l'int√©grit√©
            integrity_result = subprocess.run([
                'sqlite3', db_path, 'PRAGMA integrity_check;'
            ], capture_output=True, text=True, timeout=30)

            if integrity_result.returncode == 0:
                integrity_output = integrity_result.stdout.strip()

                if integrity_output == 'ok':
                    return {'success': True, 'message': 'Base SQLite int√®gre'}
                else:
                    # Tentative de r√©paration
                    repair_result = subprocess.run([
                        'sqlite3', db_path, 'REINDEX;'
                    ], capture_output=True, timeout=60)

                    return {
                        'success': repair_result.returncode == 0,
                        'integrity_issues': integrity_output,
                        'repaired': repair_result.returncode == 0
                    }
            else:
                return {
                    'success': False,
                    'error': f'Erreur v√©rification int√©grit√©: {integrity_result.stderr}'
                }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _repair_postgresql_database(self, db_url: str) -> Dict:
        """R√©parer une base PostgreSQL"""
        try:
            # Parser l'URL
            import re
            pattern = r'postgresql://([^:]+):([^@]+)@([^:]+):(\d+)/(.+)'
            match = re.match(pattern, db_url)

            if not match:
                return {'success': False, 'error': 'Format URL PostgreSQL invalide'}

            user, password, host, port, database = match.groups()

            # Commandes de r√©paration PostgreSQL
            commands = [
                f'REINDEX DATABASE {database};',
                f'VACUUM ANALYZE {database};',
                f'CHECKPOINT;'
            ]

            env = os.environ.copy()
            env['PGPASSWORD'] = password

            success_count = 0
            for cmd in commands:
                try:
                    result = subprocess.run([
                        'psql',
                        f'--host={host}',
                        f'--port={port}',
                        f'--username={user}',
                        f'--dbname={database}',
                        '--no-password',
                        '--command', cmd
                    ], env=env, capture_output=True, text=True, timeout=300)

                    if result.returncode == 0:
                        success_count += 1

                except Exception as e:
                    self.logger.warning(f"Erreur commande r√©paration PostgreSQL: {cmd} - {e}")

            return {
                'success': success_count > 0,
                'commands_executed': success_count,
                'total_commands': len(commands)
            }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _restart_application(self) -> Dict:
        """Red√©marrer l'application"""
        try:
            # Red√©marrer l'application Flask via supervisor ou systemd
            result = subprocess.run([
                'sudo', 'systemctl', 'restart', 'passprint'
            ], capture_output=True, text=True, timeout=60)

            return {
                'success': result.returncode == 0,
                'output': result.stdout,
                'error': result.stderr
            }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _clear_problematic_caches(self) -> Dict:
        """Vider les caches probl√©matiques"""
        try:
            from redis_cache import clear_cache

            # Vider tous les caches
            cache_cleared = clear_cache()

            return {
                'success': True,
                'cache_cleared': cache_cleared
            }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _restart_celery_workers(self) -> Dict:
        """Red√©marrer les workers Celery"""
        try:
            # Red√©marrer les workers Celery
            result = subprocess.run([
                'sudo', 'systemctl', 'restart', 'celery-workers'
            ], capture_output=True, text=True, timeout=60)

            return {
                'success': result.returncode == 0,
                'output': result.stdout,
                'error': result.stderr
            }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _find_latest_valid_backup(self) -> str:
        """Trouver la derni√®re sauvegarde valide"""
        try:
            backup_dir = Path('backups')
            if not backup_dir.exists():
                return None

            # Chercher les sauvegardes r√©centes
            backup_files = []
            for backup_file in backup_dir.glob('passprint_*'):
                if backup_file.is_file() and backup_file.stat().st_mtime > (datetime.now() - timedelta(hours=24)).timestamp():
                    backup_files.append(backup_file)

            if not backup_files:
                return None

            # Retourner la plus r√©cente
            latest_backup = max(backup_files, key=lambda x: x.stat().st_mtime)
            return str(latest_backup)

        except Exception as e:
            self.logger.error(f"Erreur recherche sauvegarde valide: {e}")
            return None

    def _restore_from_backup(self, backup_path: str) -> Dict:
        """Restaurer depuis une sauvegarde"""
        try:
            # Restaurer la base de donn√©es
            db_restore_success, db_result = backup_system.restore_database(backup_path)

            # Restaurer les fichiers si c'est une sauvegarde compl√®te
            files_restore_success = True
            files_result = "Pas de fichiers √† restaurer"

            if 'full' in backup_path or 'files' in backup_path:
                files_restore_success, files_result = backup_system.restore_files(backup_path)

            return {
                'success': db_restore_success and files_restore_success,
                'database_restored': db_restore_success,
                'files_restored': files_restore_success,
                'details': {
                    'database': db_result,
                    'files': files_result
                }
            }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _create_recovery_report(self, recovery_result: dict):
        """Cr√©er un rapport de r√©cup√©ration"""
        try:
            report = {
                'recovery_timestamp': datetime.utcnow().isoformat(),
                'recovery_result': recovery_result,
                'system_status': self._get_current_system_status(),
                'next_steps': self._get_next_steps(recovery_result)
            }

            # Sauvegarder le rapport
            report_file = Path('backups') / f'recovery_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            with open(report_file, 'w') as f:
                json.dump(report, f, indent=2)

            # Envoyer le rapport par email si configur√©
            self._send_recovery_report_email(report)

        except Exception as e:
            self.logger.error(f"Erreur cr√©ation rapport r√©cup√©ration: {e}")

    def _get_current_system_status(self) -> Dict:
        """Obtenir le statut actuel du syst√®me"""
        try:
            from monitoring_alerting import MetricsCollector

            collector = MetricsCollector()
            collector.collect_all_metrics()

            return {
                'timestamp': datetime.utcnow().isoformat(),
                'system_healthy': collector.metrics.get('application', {}).get('health', {}).get('healthy', False),
                'database_healthy': collector.metrics.get('database', {}).get('stats', {}).get('connection_healthy', False),
                'cache_healthy': collector.metrics.get('cache', {}).get('health', {}).get('status') == 'healthy'
            }

        except Exception as e:
            return {'error': str(e)}

    def _get_next_steps(self, recovery_result: dict) -> List[str]:
        """Obtenir les prochaines √©tapes recommand√©es"""
        next_steps = []

        if not recovery_result.get('success', False):
            next_steps.append("R√©cup√©ration automatique √©chou√©e - Intervention manuelle requise")
            next_steps.append("Contacter l'√©quipe d'astreinte")
            next_steps.append("Analyser les logs d'erreur en d√©tail")

        next_steps.append("V√©rifier que tous les services sont op√©rationnels")
        next_steps.append("Tester les fonctionnalit√©s critiques")
        next_steps.append("Cr√©er un rapport d'incident")

        return next_steps

    def _send_recovery_report_email(self, report: dict):
        """Envoyer le rapport de r√©cup√©ration par email"""
        try:
            # Configuration email
            smtp_server = os.getenv('SMTP_SERVER', 'smtp.gmail.com')
            smtp_port = int(os.getenv('SMTP_PORT', '587'))
            smtp_username = os.getenv('SMTP_USERNAME')
            smtp_password = os.getenv('SMTP_PASSWORD')

            if not smtp_username or not smtp_password:
                return

            # Destinataires
            recipients = os.getenv('RECOVERY_EMAIL_RECIPIENTS', 'admin@passprint.com').split(',')

            # Cr√©er l'email
            msg = MimeMultipart()
            msg['From'] = smtp_username
            msg['To'] = ', '.join(recipients)
            msg['Subject'] = f"[PassPrint] Rapport de r√©cup√©ration - {report['recovery_timestamp']}"

            # Corps de l'email
            body = f"""
            Rapport de r√©cup√©ration PassPrint

            Timestamp: {report['recovery_timestamp']}
            Succ√®s: {'Oui' if report['recovery_result'].get('success', False) else 'Non'}

            Actions prises:
            {chr(10).join(f"- {action}" for action in report['recovery_result'].get('actions_taken', []))}

            Erreurs rencontr√©es:
            {chr(10).join(f"- {error}" for error in report['recovery_result'].get('errors', []))}

            √âtat syst√®me actuel:
            - Syst√®me sain: {'Oui' if report['system_status'].get('system_healthy', False) else 'Non'}
            - Base de donn√©es: {'Saine' if report['system_status'].get('database_healthy', False) else 'Probl√©matique'}
            - Cache: {'Sain' if report['system_status'].get('cache_healthy', False) else 'Probl√©matique'}

            Prochaines √©tapes:
            {chr(10).join(f"- {step}" for step in report.get('next_steps', []))}

            Ce rapport a √©t√© g√©n√©r√© automatiquement par le syst√®me de r√©cup√©ration apr√®s d√©sastre.
            """

            msg.attach(MimeText(body, 'plain'))

            # Envoyer l'email
            server = smtplib.SMTP(smtp_server, smtp_port)
            server.starttls()
            server.login(smtp_username, smtp_password)
            server.sendmail(smtp_username, recipients, msg.as_string())
            server.quit()

            self.logger.info("Rapport de r√©cup√©ration envoy√© par email")

        except Exception as e:
            self.logger.error(f"Erreur envoi email rapport r√©cup√©ration: {e}")

    def create_recovery_scripts(self):
        """Cr√©er les scripts de r√©cup√©ration automatique"""
        try:
            scripts_created = []

            # Script de r√©cup√©ration de base de donn√©es
            db_script = self._create_database_recovery_script()
            scripts_created.append(db_script)

            # Script de r√©cup√©ration de fichiers
            files_script = self._create_files_recovery_script()
            scripts_created.append(files_script)

            # Script de r√©cup√©ration compl√®te
            full_script = self._create_full_recovery_script()
            scripts_created.append(full_script)

            # Script de v√©rification post-r√©cup√©ration
            verify_script = self._create_verification_script()
            scripts_created.append(verify_script)

            self.logger.info(f"Scripts de r√©cup√©ration cr√©√©s: {len(scripts_created)}")
            return scripts_created

        except Exception as e:
            self.logger.error(f"Erreur cr√©ation scripts r√©cup√©ration: {e}")
            return []

    def _create_database_recovery_script(self) -> str:
        """Cr√©er le script de r√©cup√©ration de base de donn√©es"""
        script_content = """#!/bin/bash
# Script de r√©cup√©ration de base de donn√©es PassPrint
# Usage: ./recover_database.sh [backup_file]

set -e

BACKUP_FILE=${1:-"latest"}
LOG_FILE="/var/log/passprint/database_recovery.log"

echo "$(date): D√©marrage r√©cup√©ration base de donn√©es" >> "$LOG_FILE"

if [ "$BACKUP_FILE" = "latest" ]; then
    # Trouver la derni√®re sauvegarde
    BACKUP_FILE=$(find /backups -name "passprint_*sqlite*" -o -name "passprint_*postgres*" | sort -r | head -1)
fi

if [ -z "$BACKUP_FILE" ]; then
    echo "$(date): Aucune sauvegarde trouv√©e" >> "$LOG_FILE"
    exit 1
fi

echo "$(date): Utilisation sauvegarde: $BACKUP_FILE" >> "$LOG_FILE"

# Arr√™ter l'application
sudo systemctl stop passprint

# Cr√©er une sauvegarde d'urgence
EMERGENCY_BACKUP="/backups/emergency_$(date +%Y%m%d_%H%M%S).db"
cp /opt/passprint-website/passprint.db "$EMERGENCY_BACKUP" 2>/dev/null || true

# Restaurer la sauvegarde
if [[ "$BACKUP_FILE" == *"postgres"* ]]; then
    # Restauration PostgreSQL
    pg_restore -h localhost -U passprint -d passprint_prod -c "$BACKUP_FILE"
elif [[ "$BACKUP_FILE" == *"sqlite"* ]]; then
    # Restauration SQLite
    gunzip -c "$BACKUP_FILE" > /opt/passprint-website/passprint.db
    chown passprint:passprint /opt/passprint-website/passprint.db
fi

# Red√©marrer l'application
sudo systemctl start passprint

# V√©rification
sleep 10
curl -f http://localhost:5000/api/health || exit 1

echo "$(date): R√©cup√©ration base de donn√©es termin√©e avec succ√®s" >> "$LOG_FILE"
"""

        script_path = self.recovery_scripts_dir / 'recover_database.sh'
        with open(script_path, 'w') as f:
            f.write(script_content)

        script_path.chmod(0o755)
        return str(script_path)

    def _create_files_recovery_script(self) -> str:
        """Cr√©er le script de r√©cup√©ration de fichiers"""
        script_content = """#!/bin/bash
# Script de r√©cup√©ration de fichiers PassPrint
# Usage: ./recover_files.sh [backup_file]

set -e

BACKUP_FILE=${1:-"latest"}
LOG_FILE="/var/log/passprint/files_recovery.log"

echo "$(date): D√©marrage r√©cup√©ration fichiers" >> "$LOG_FILE"

if [ "$BACKUP_FILE" = "latest" ]; then
    # Trouver la derni√®re sauvegarde de fichiers
    BACKUP_FILE=$(find /backups -name "*files*" | sort -r | head -1)
fi

if [ -z "$BACKUP_FILE" ]; then
    echo "$(date): Aucune sauvegarde de fichiers trouv√©e" >> "$LOG_FILE"
    exit 1
fi

echo "$(date): Utilisation sauvegarde: $BACKUP_FILE" >> "$LOG_FILE"

# Cr√©er des sauvegardes des fichiers actuels
for dir in uploads static logs; do
    if [ -d "/opt/passprint-website/$dir" ]; then
        BACKUP_DIR="/backups/emergency_files_$(date +%Y%m%d_%H%M%S)/$dir"
        mkdir -p "$BACKUP_DIR"
        cp -r "/opt/passprint-website/$dir" "$BACKUP_DIR" 2>/dev/null || true
    fi
done

# Extraire la sauvegarde
cd /opt/passprint-website
tar -xzf "$BACKUP_FILE"

# Restaurer les permissions
chown -R passprint:passprint uploads static logs

echo "$(date): R√©cup√©ration fichiers termin√©e avec succ√®s" >> "$LOG_FILE"
"""

        script_path = self.recovery_scripts_dir / 'recover_files.sh'
        with open(script_path, 'w') as f:
            f.write(script_content)

        script_path.chmod(0o755)
        return str(script_path)

    def _create_full_recovery_script(self) -> str:
        """Cr√©er le script de r√©cup√©ration compl√®te"""
        script_content = """#!/bin/bash
# Script de r√©cup√©ration compl√®te PassPrint
# Usage: ./recover_full.sh

set -e

LOG_FILE="/var/log/passprint/full_recovery.log"

echo "$(date): D√©marrage r√©cup√©ration compl√®te" >> "$LOG_FILE"

# 1. R√©cup√©ration base de donn√©es
echo "$(date): √âtape 1/4 - R√©cup√©ration base de donn√©es" >> "$LOG_FILE"
./recover_database.sh

# 2. R√©cup√©ration fichiers
echo "$(date): √âtape 2/4 - R√©cup√©ration fichiers" >> "$LOG_FILE"
./recover_files.sh

# 3. Red√©marrage services
echo "$(date): √âtape 3/4 - Red√©marrage services" >> "$LOG_FILE"
sudo systemctl restart redis postgresql nginx passprint celery-workers

# 4. V√©rification
echo "$(date): √âtape 4/4 - V√©rification" >> "$LOG_FILE"
sleep 30

# V√©rifications de base
curl -f http://localhost:5000/api/health || exit 1
curl -f http://localhost:5000/api/products || exit 1

echo "$(date): R√©cup√©ration compl√®te termin√©e avec succ√®s" >> "$LOG_FILE"
"""

        script_path = self.recovery_scripts_dir / 'recover_full.sh'
        with open(script_path, 'w') as f:
            f.write(script_content)

        script_path.chmod(0o755)
        return str(script_path)

    def _create_verification_script(self) -> str:
        """Cr√©er le script de v√©rification post-r√©cup√©ration"""
        script_content = """#!/bin/bash
# Script de v√©rification post-r√©cup√©ration PassPrint
# Usage: ./verify_recovery.sh

LOG_FILE="/var/log/passprint/verification.log"

echo "$(date): D√©marrage v√©rification post-r√©cup√©ration" >> "$LOG_FILE"

ERRORS=0

# 1. V√©rifier la sant√© de l'API
echo "$(date): V√©rification API..." >> "$LOG_FILE"
if curl -f http://localhost:5000/api/health > /dev/null 2>&1; then
    echo "$(date): ‚úÖ API op√©rationnelle" >> "$LOG_FILE"
else
    echo "$(date): ‚ùå API non op√©rationnelle" >> "$LOG_FILE"
    ERRORS=$((ERRORS + 1))
fi

# 2. V√©rifier la base de donn√©es
echo "$(date): V√©rification base de donn√©es..." >> "$LOG_FILE"
if curl -f http://localhost:5000/api/products > /dev/null 2>&1; then
    echo "$(date): ‚úÖ Base de donn√©es accessible" >> "$LOG_FILE"
else
    echo "$(date): ‚ùå Base de donn√©es inaccessible" >> "$LOG_FILE"
    ERRORS=$((ERRORS + 1))
fi

# 3. V√©rifier les services
echo "$(date): V√©rification services..." >> "$LOG_FILE"
SERVICES=("redis" "postgresql" "nginx" "passprint")
for service in "${SERVICES[@]}"; do
    if sudo systemctl is-active --quiet "$service"; then
        echo "$(date): ‚úÖ Service $service actif" >> "$LOG_FILE"
    else
        echo "$(date): ‚ùå Service $service inactif" >> "$LOG_FILE"
        ERRORS=$((ERRORS + 1))
    fi
done

# 4. V√©rifier les sauvegardes r√©centes
echo "$(date): V√©rification sauvegardes..." >> "$LOG_FILE"
if find /backups -name "passprint_*" -mtime -1 | grep -q .; then
    echo "$(date): ‚úÖ Sauvegardes r√©centes trouv√©es" >> "$LOG_FILE"
else
    echo "$(date): ‚ö†Ô∏è Aucune sauvegarde r√©cente" >> "$LOG_FILE"
fi

# R√©sultat final
if [ $ERRORS -eq 0 ]; then
    echo "$(date): ‚úÖ V√©rification r√©ussie - Syst√®me op√©rationnel" >> "$LOG_FILE"
    exit 0
else
    echo "$(date): ‚ùå $ERRORS erreurs d√©tect√©es" >> "$LOG_FILE"
    exit 1
fi
"""

        script_path = self.recovery_scripts_dir / 'verify_recovery.sh'
        with open(script_path, 'w') as f:
            f.write(script_content)

        script_path.chmod(0o755)
        return str(script_path)

    def simulate_disaster_scenario(self, scenario_type: str) -> Dict:
        """Simuler un sc√©nario de d√©sastre pour les tests"""
        try:
            simulation_result = {
                'scenario': scenario_type,
                'timestamp': datetime.utcnow().isoformat(),
                'steps': [],
                'success': True
            }

            if scenario_type == 'database_failure':
                simulation_result['steps'] = self._simulate_database_failure()
            elif scenario_type == 'disk_space_exhaustion':
                simulation_result['steps'] = self._simulate_disk_space_exhaustion()
            elif scenario_type == 'high_cpu_usage':
                simulation_result['steps'] = self._simulate_high_cpu_usage()
            elif scenario_type == 'security_incident':
                simulation_result['steps'] = self._simulate_security_incident()
            else:
                return {'success': False, 'error': f'Sc√©nario non support√©: {scenario_type}'}

            return simulation_result

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _simulate_database_failure(self) -> List[str]:
        """Simuler une panne de base de donn√©es"""
        steps = [
            "Arr√™t du service PostgreSQL",
            "Suppression du fichier de base de donn√©es",
            "Tentative de connexion √©chou√©e",
            "D√©tection du d√©sastre",
            "R√©cup√©ration automatique",
            "Restauration depuis sauvegarde",
            "V√©rification de l'int√©grit√©"
        ]

        # En d√©veloppement, on simule seulement
        self.logger.info("Simulation panne base de donn√©es (mode d√©veloppement)")

        return steps

    def _simulate_disk_space_exhaustion(self) -> List[str]:
        """Simuler l'√©puisement de l'espace disque"""
        steps = [
            "Cr√©ation de fichiers volumineux",
            "Surveillance de l'espace disque",
            "D√©tection du seuil critique",
            "D√©clenchement de l'alerte",
            "Nettoyage automatique",
            "Lib√©ration d'espace"
        ]

        self.logger.info("Simulation √©puisement espace disque (mode d√©veloppement)")

        return steps

    def _simulate_high_cpu_usage(self) -> List[str]:
        """Simuler une utilisation CPU √©lev√©e"""
        steps = [
            "Lancement de processus intensifs",
            "Surveillance de l'utilisation CPU",
            "D√©tection du seuil √©lev√©",
            "D√©clenchement de l'alerte",
            "Optimisation automatique",
            "Retour √† la normale"
        ]

        self.logger.info("Simulation utilisation CPU √©lev√©e (mode d√©veloppement)")

        return steps

    def _simulate_security_incident(self) -> List[str]:
        """Simuler un incident de s√©curit√©"""
        steps = [
            "Tentatives de connexion multiples",
            "D√©tection d'activit√© suspecte",
            "Verrouillage automatique du compte",
            "D√©clenchement de l'alerte s√©curit√©",
            "Audit des acc√®s",
            "Mesures correctives"
        ]

        self.logger.info("Simulation incident s√©curit√© (mode d√©veloppement)")

        return steps

# Instance globale du gestionnaire de r√©cup√©ration
disaster_recovery_manager = DisasterRecoveryManager()

def detect_disaster(system_metrics: dict) -> Dict:
    """Fonction utilitaire pour d√©tecter un d√©sastre"""
    return disaster_recovery_manager.detect_disaster(system_metrics)

def initiate_recovery(disaster_info: dict) -> Dict:
    """Fonction utilitaire pour initier la r√©cup√©ration"""
    return disaster_recovery_manager.initiate_automatic_recovery(disaster_info)

def create_recovery_scripts():
    """Fonction utilitaire pour cr√©er les scripts de r√©cup√©ration"""
    return disaster_recovery_manager.create_recovery_scripts()

def simulate_disaster_scenario(scenario_type: str) -> Dict:
    """Fonction utilitaire pour simuler un sc√©nario de d√©sastre"""
    return disaster_recovery_manager.simulate_disaster_scenario(scenario_type)

if __name__ == "__main__":
    print("üõ°Ô∏è  Syst√®me de r√©cup√©ration apr√®s d√©sastre PassPrint")

    # Cr√©er les scripts de r√©cup√©ration
    scripts = create_recovery_scripts()
    print(f"‚úÖ Scripts de r√©cup√©ration cr√©√©s: {len(scripts)}")

    # Test de d√©tection de d√©sastre
    test_metrics = {
        'system': {
            'cpu': {'percent': 95},
            'memory': {'percent': 90},
            'disk': {'percent': 85}
        },
        'database': {
            'stats': {'connection_healthy': False}
        }
    }

    disaster_info = detect_disaster(test_metrics)
    print(f"D√©tection d√©sastre: {disaster_info}")